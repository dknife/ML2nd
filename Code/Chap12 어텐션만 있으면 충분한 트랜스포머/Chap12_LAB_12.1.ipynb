{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyODj2wkZB+OhfjoTSPYucqa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ce4a4e1f55794d55b1e2e9f492e0507a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ae09b40212f47f3a5bce320593dc6de","IPY_MODEL_9e5b4aa8b28247e5b2343e097de4ae77","IPY_MODEL_aee6d35a639b4bd2a29fca8b5561a6cc"],"layout":"IPY_MODEL_8a94280430e74fd3acf6577aa26fe852"}},"3ae09b40212f47f3a5bce320593dc6de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd2d06050ac64490a4a70b254e100971","placeholder":"​","style":"IPY_MODEL_ee3d21cea58f4d5cbdbdd8411b3aad22","value":"config.json: "}},"9e5b4aa8b28247e5b2343e097de4ae77":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84264d6db8764c7b8313053509218b4c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bca73e35b8494d8e875ff7b6b688f21a","value":1}},"aee6d35a639b4bd2a29fca8b5561a6cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0705d8105e8f482d857c2a666f4faa74","placeholder":"​","style":"IPY_MODEL_a6c30deabb49427bb447e6c564c719f3","value":" 1.00k/? [00:00&lt;00:00, 47.3kB/s]"}},"8a94280430e74fd3acf6577aa26fe852":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd2d06050ac64490a4a70b254e100971":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee3d21cea58f4d5cbdbdd8411b3aad22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84264d6db8764c7b8313053509218b4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"bca73e35b8494d8e875ff7b6b688f21a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0705d8105e8f482d857c2a666f4faa74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6c30deabb49427bb447e6c564c719f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d47f0e3ee3de49a09472bed436d5f14c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6100edb60e3545729e45290b20ccee60","IPY_MODEL_1c37f3545a414875822e1210a68af332","IPY_MODEL_1e5b82843f5b4f69955471ebb464333c"],"layout":"IPY_MODEL_bd3a937f64eb4745bd11d7d374bc1954"}},"6100edb60e3545729e45290b20ccee60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d3355b693b24249966ffe9975037b9a","placeholder":"​","style":"IPY_MODEL_adecca70acc44fd0a54e7cdc81db5d79","value":"tokenizer.json: "}},"1c37f3545a414875822e1210a68af332":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04a04a83aca44acb856677a25cc1dc4f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf792fda442e40c7b971e179a030cfc7","value":1}},"1e5b82843f5b4f69955471ebb464333c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f793ccd850d44a7fa3d9321e611982c5","placeholder":"​","style":"IPY_MODEL_8eebc97186834dbe87ca1074831b3d4a","value":" 2.83M/? [00:00&lt;00:00, 54.5MB/s]"}},"bd3a937f64eb4745bd11d7d374bc1954":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d3355b693b24249966ffe9975037b9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adecca70acc44fd0a54e7cdc81db5d79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04a04a83aca44acb856677a25cc1dc4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"cf792fda442e40c7b971e179a030cfc7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f793ccd850d44a7fa3d9321e611982c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eebc97186834dbe87ca1074831b3d4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# **12. 어텐션이면 충분한 막강한 트랜스포머**\n","---\n","* 출판사 : 생능 출판사( http://www.booksr.co.kr/ )\n","* 으뜸 파이썬 저자 : 강영민, 박동규, 김성수\n","*  소스코드 저장소 : https://github.com/dknife/ML2nd\n","*  저작권 : 본 노트북 코드는 자유롭게 배포가능하지만 위의 출판사, 저서, 저자표기와 함께 배포해 주십시오.\n","---"],"metadata":{"id":"CtvXAwAdDclv"}},{"cell_type":"markdown","source":["### **LAB 12-1 트랜스포머를 이용한 챗봇**"],"metadata":{"id":"YmmZTJlGDtQK"}},{"cell_type":"code","source":["# ================================\n","# 1. 설치 및 Import\n","# ================================\n","# !pip install transformers tensorflow pandas -q\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers, optimizers\n","import numpy as np\n","import pandas as pd\n","import re\n","from transformers import AutoTokenizer"],"metadata":{"id":"eSfqi_03MiwT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================================\n","# 2. 데이터 다운로드 & 로드\n","# ================================\n","site = \"https://raw.githubusercontent.com/\"\n","filepath = \"songys/Chatbot_data/master/ChatbotData.csv\"\n","\n","df = pd.read_csv(site+filepath)\n","print(f\"총 데이터 수: {len(df)}\")\n","df[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"Dvt66Hk4POE3","executionInfo":{"status":"ok","timestamp":1764254286572,"user_tz":-540,"elapsed":512,"user":{"displayName":"Young-Min Kang","userId":"11805267479837045412"}},"outputId":"56b5c7c7-64ff-47a5-acff-1af3cf4573e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["총 데이터 수: 11823\n"]},{"output_type":"execute_result","data":{"text/plain":["                         Q                   A  label\n","0                   12시 땡!          하루가 또 가네요.      0\n","1              1지망 학교 떨어졌어           위로해 드립니다.      0\n","2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n","3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n","4                  PPL 심하네          눈살이 찌푸려지죠.      0\n","5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n","6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n","7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n","8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n","9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0"],"text/html":["\n","  <div id=\"df-d2768dc1-738c-40f1-8d7b-79361736a6ca\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12시 땡!</td>\n","      <td>하루가 또 가네요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1지망 학교 떨어졌어</td>\n","      <td>위로해 드립니다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3박4일 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3박4일 정도 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL 심하네</td>\n","      <td>눈살이 찌푸려지죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>SD카드 망가졌어</td>\n","      <td>다시 새로 사는 게 마음 편해요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>SD카드 안돼</td>\n","      <td>다시 새로 사는 게 마음 편해요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n","      <td>잘 모르고 있을 수도 있어요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n","      <td>시간을 정하고 해보세요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n","      <td>시간을 정하고 해보세요.</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2768dc1-738c-40f1-8d7b-79361736a6ca')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d2768dc1-738c-40f1-8d7b-79361736a6ca button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d2768dc1-738c-40f1-8d7b-79361736a6ca');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-e1e6c96e-59f1-42b7-9250-c1e46fa8e583\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1e6c96e-59f1-42b7-9250-c1e46fa8e583')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-e1e6c96e-59f1-42b7-9250-c1e46fa8e583 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df[:10]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"SNS \\uc2dc\\uac04\\ub0ad\\ube44\\uc778 \\uac70 \\uc544\\ub294\\ub370 \\ub9e4\\uc77c \\ud558\\ub294 \\uc911\",\n          \"1\\uc9c0\\ub9dd \\ud559\\uad50 \\ub5a8\\uc5b4\\uc84c\\uc5b4\",\n          \"SD\\uce74\\ub4dc \\ub9dd\\uac00\\uc84c\\uc5b4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"\\ud558\\ub8e8\\uac00 \\ub610 \\uac00\\ub124\\uc694.\",\n          \"\\uc704\\ub85c\\ud574 \\ub4dc\\ub9bd\\ub2c8\\ub2e4.\",\n          \"\\uc798 \\ubaa8\\ub974\\uace0 \\uc788\\uc744 \\uc218\\ub3c4 \\uc788\\uc5b4\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# ================================\n","# 3. 전처리\n","# ================================\n","def clean_text(t):\n","    return re.sub(r\"[?.!,]\", \"\", str(t)).strip()\n","\n","questions = df['Q'].apply(clean_text).tolist()\n","answers = [f\"<START> {clean_text(a)} <END>\" for a in df['A'].tolist()]"],"metadata":{"id":"0H7EmX6UVvuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================================\n","# 4. KoGPT2 토크나이저\n","# ================================\n","tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<START>\", \"<END>\", \"[SEP]\"]})\n","\n","vocab_size = len(tokenizer)\n","PAD_ID = np.int32(tokenizer.pad_token_id)\n","START_ID = np.int32(tokenizer.convert_tokens_to_ids(\"<START>\"))\n","END_ID = np.int32(tokenizer.convert_tokens_to_ids(\"<END>\"))"],"metadata":{"id":"rzGJ11e2Vw2z","executionInfo":{"status":"ok","timestamp":1764254288640,"user_tz":-540,"elapsed":2014,"user":{"displayName":"Young-Min Kang","userId":"11805267479837045412"}},"colab":{"base_uri":"https://localhost:8080/","height":185,"referenced_widgets":["ce4a4e1f55794d55b1e2e9f492e0507a","3ae09b40212f47f3a5bce320593dc6de","9e5b4aa8b28247e5b2343e097de4ae77","aee6d35a639b4bd2a29fca8b5561a6cc","8a94280430e74fd3acf6577aa26fe852","cd2d06050ac64490a4a70b254e100971","ee3d21cea58f4d5cbdbdd8411b3aad22","84264d6db8764c7b8313053509218b4c","bca73e35b8494d8e875ff7b6b688f21a","0705d8105e8f482d857c2a666f4faa74","a6c30deabb49427bb447e6c564c719f3","d47f0e3ee3de49a09472bed436d5f14c","6100edb60e3545729e45290b20ccee60","1c37f3545a414875822e1210a68af332","1e5b82843f5b4f69955471ebb464333c","bd3a937f64eb4745bd11d7d374bc1954","6d3355b693b24249966ffe9975037b9a","adecca70acc44fd0a54e7cdc81db5d79","04a04a83aca44acb856677a25cc1dc4f","cf792fda442e40c7b971e179a030cfc7","f793ccd850d44a7fa3d9321e611982c5","8eebc97186834dbe87ca1074831b3d4a"]},"outputId":"6e764438-2879-47da-dd13-c16ff818ec2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4a4e1f55794d55b1e2e9f492e0507a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d47f0e3ee3de49a09472bed436d5f14c"}},"metadata":{}}]},{"cell_type":"code","source":["# ================================\n","# 5. MAX_LEN 계산 (95 percentile → 40 제한)\n","# ================================\n","def get_length(text):\n","    return len(tokenizer.encode(f\"<START> {text} [SEP]\", add_special_tokens=False))\n","\n","q_lens = [get_length(q) for q in questions]\n","a_lens = [get_length(a.replace(\"<START> \", \"\").replace(\" <END>\", \"\")) for a in answers]\n","all_lens = q_lens + a_lens\n","MAX_LEN = min(int(np.percentile(all_lens, 95)), 40)\n","print(f\"MAX_LEN: {MAX_LEN}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C17BWMrgV18g","executionInfo":{"status":"ok","timestamp":1764254290097,"user_tz":-540,"elapsed":1459,"user":{"displayName":"Young-Min Kang","userId":"11805267479837045412"}},"outputId":"f3d8f4e0-905f-46aa-badd-281f818e4e37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MAX_LEN: 15\n"]}]},{"cell_type":"code","source":["# ================================\n","# 6. 데이터 인코딩\n","# ================================\n","def encode_input(text):\n","    return tokenizer.encode(\n","        f\"<START> {text} [SEP]\",\n","        max_length=MAX_LEN,\n","        truncation=True,\n","        padding='max_length',\n","        add_special_tokens=False\n","    )\n","\n","def encode_output(text):\n","    return tokenizer.encode(text, max_length=MAX_LEN, truncation=True, padding='max_length')"],"metadata":{"id":"YmXghMFWcsto"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"인코딩 중...\")\n","encoder_input = np.array([encode_input(q) for q in questions], dtype=np.int32)\n","full_answers = [encode_output(a) for a in answers]\n","print(f\"인코딩 완료...{encoder_input.shape} : {len(full_answers)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2k9eTSyFcuxk","executionInfo":{"status":"ok","timestamp":1764254291874,"user_tz":-540,"elapsed":1760,"user":{"displayName":"Young-Min Kang","userId":"11805267479837045412"}},"outputId":"420a0888-6ffe-4564-c597-f4675b9aca39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["인코딩 중...\n","인코딩 완료...(11823, 15) : 11823\n"]}]},{"cell_type":"code","source":["decoder_input_list = []\n","decoder_output_list = []\n","\n","for seq in full_answers:\n","    if len(seq) <= 1:\n","        continue\n","    dec_in = [START_ID] + seq[:-1]\n","    dec_out = seq[1:]\n","    dec_in += [PAD_ID] * (MAX_LEN - len(dec_in))\n","    dec_out += [PAD_ID] * (MAX_LEN - len(dec_out))\n","    decoder_input_list.append(dec_in)\n","    decoder_output_list.append(dec_out)\n","\n","decoder_input = np.array(decoder_input_list, dtype=np.int32)\n","decoder_output = np.array(decoder_output_list, dtype=np.int32)\n","\n","print(f\"Shapes: {encoder_input.shape}, {decoder_input.shape}, {decoder_output.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2NjVPWfMfAx-","executionInfo":{"status":"ok","timestamp":1764254292208,"user_tz":-540,"elapsed":4,"user":{"displayName":"Young-Min Kang","userId":"11805267479837045412"}},"outputId":"4f0bed91-5e61-4a1c-bb9f-78298306c15f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shapes: (11823, 15), (11823, 15), (11823, 15)\n"]}]},{"cell_type":"code","source":["# ================================\n","# 7. 고정된 Sin/Cos Positional Encoding (파라미터 0!)\n","# ================================\n","def get_positional_encoding(max_len, d_model):\n","    pe = np.zeros((max_len, d_model))\n","    position = np.arange(0, max_len)[:, np.newaxis]\n","    div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n","    pe[:, 0::2] = np.sin(position * div_term)\n","    pe[:, 1::2] = np.cos(position * div_term)\n","    return tf.constant(pe, dtype=tf.float32)  # (max_len, d_model)\n","\n","pos_encoding = get_positional_encoding(MAX_LEN, 256)"],"metadata":{"id":"w523tBvAkgmx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_padding_mask(seq):\n","    return tf.cast(tf.math.equal(seq, PAD_ID),\n","                   tf.float32)[:, tf.newaxis, tf.newaxis, :]\n"],"metadata":{"id":"4URPSDbznraz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def create_look_ahead_mask(seq_len):\n","    return 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","\n"],"metadata":{"id":"F3KnHkXkwjaO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_decoder_mask(dec_input):\n","    seq_len = tf.shape(dec_input)[1]\n","    batch_size = tf.shape(dec_input)[0]\n","    look_ahead = create_look_ahead_mask(seq_len)[tf.newaxis,\n","                                                 tf.newaxis, :, :]\n","    look_ahead = tf.tile(look_ahead, [batch_size, 1, 1, 1])\n","    dec_padding = create_padding_mask(dec_input)\n","    dec_padding = tf.tile(dec_padding, [1, 1, seq_len, 1])\n","    return tf.maximum(look_ahead, dec_padding)"],"metadata":{"id":"BWGYQORTwmQM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================================\n","# 9. Multi-Head Attention\n","# ================================\n","class MultiHeadAttention(layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","        self.depth = d_model // num_heads\n","        self.wq = layers.Dense(d_model, use_bias=False)\n","        self.wk = layers.Dense(d_model, use_bias=False)\n","        self.wv = layers.Dense(d_model, use_bias=False)\n","        self.wo = layers.Dense(d_model)\n","\n","    def split_heads(self, x, batch):\n","        x = tf.reshape(x, (batch, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, [0, 2, 1, 3])\n","\n","    def call(self, q, k, v, mask=None):\n","        batch = tf.shape(q)[0]\n","        q, k, v = self.wq(q), self.wk(k), self.wv(v)\n","        q, k, v = self.split_heads(q, batch), self.split_heads(k, batch), self.split_heads(v, batch)\n","\n","        matmul = tf.matmul(q, k, transpose_b=True)\n","        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","        scaled = matmul / tf.math.sqrt(dk)\n","\n","        if mask is not None:\n","            scaled = scaled + (mask * -1e9)\n","\n","        attn = tf.nn.softmax(scaled, axis=-1)\n","        out = tf.matmul(attn, v)\n","        out = tf.transpose(out, [0, 2, 1, 3])\n","        out = tf.reshape(out, (batch, -1, self.d_model))\n","        return self.wo(out)"],"metadata":{"id":"t2GbZNm1wpQw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================================\n","# 10. Encoder / Decoder Layer\n","# ================================\n","class EncoderLayer(layers.Layer):\n","    def __init__(self, d_model, num_heads, dff):\n","        super().__init__()\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = tf.keras.Sequential([layers.Dense(dff, activation='relu'), layers.Dense(d_model)])\n","        self.ln1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.ln2 = layers.LayerNormalization(epsilon=1e-6)\n","\n","    def call(self, x, mask):\n","        x = self.ln1(x + self.mha(x, x, x, mask))\n","        return self.ln2(x + self.ffn(x))"],"metadata":{"id":"I3DtFfFmAjTq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DecoderLayer(layers.Layer):\n","    def __init__(self, d_model, num_heads, dff):\n","        super().__init__()\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = tf.keras.Sequential([layers.Dense(dff, activation='relu'), layers.Dense(d_model)])\n","        self.ln1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.ln2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.ln3 = layers.LayerNormalization(epsilon=1e-6)\n","\n","    def call(self, x, enc, look_mask, pad_mask):\n","        x = self.ln1(x + self.mha1(x, x, x, look_mask))\n","        x = self.ln2(x + self.mha2(x, enc, enc, pad_mask))\n","        return self.ln3(x + self.ffn(x))\n"],"metadata":{"id":"D6uH6_LUAlDt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================================\n","# 11. 모델 정의 (KerasTensor 오류 해결!)\n","# ================================\n","def build_transformer(vocab_size, num_layers=3, d_model=256, num_heads=8, dff=512, max_len=MAX_LEN):\n","    enc_in = layers.Input((max_len,), name='enc')\n","    dec_in = layers.Input((max_len,), name='dec')\n","\n","    enc_mask = layers.Lambda(create_padding_mask, output_shape=(1, 1, max_len))(enc_in)\n","    dec_mask = layers.Lambda(create_decoder_mask, output_shape=(1, max_len, max_len))(dec_in)\n","\n","    # Token Embedding\n","    token_emb = layers.Embedding(vocab_size, d_model)\n","    enc_emb = token_emb(enc_in)\n","    dec_emb = token_emb(dec_in)\n","\n","    # 고정된 Positional Encoding 추가 (Lambda로 감싸기!)\n","    def add_pe(x, pe):\n","        seq_len = tf.shape(x)[1]\n","        return x + pe[:seq_len, :]\n","\n","    enc_emb = layers.Lambda(lambda x: add_pe(x, pos_encoding))(enc_emb)\n","    dec_emb = layers.Lambda(lambda x: add_pe(x, pos_encoding))(dec_emb)\n","\n","    enc = enc_emb\n","    for _ in range(num_layers):\n","        enc = EncoderLayer(d_model, num_heads, dff)(enc, enc_mask)\n","\n","    dec = dec_emb\n","    for _ in range(num_layers):\n","        dec = DecoderLayer(d_model, num_heads, dff)(dec, enc, dec_mask, enc_mask)\n","\n","    logits = layers.Dense(vocab_size)(dec)\n","    return tf.keras.Model([enc_in, dec_in], logits)\n","\n","model = build_transformer(vocab_size, num_layers=3, d_model=256, num_heads=8, dff=512, max_len=MAX_LEN)\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":777},"id":"x42sMQ8AAne3","executionInfo":{"status":"ok","timestamp":1764254295581,"user_tz":-540,"elapsed":3068,"user":{"displayName":"Young-Min Kang","userId":"11805267479837045412"}},"outputId":"00267467-61a3-4485-fca9-e42612ac7be2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional_6\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ dec (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ enc (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │ \u001b[38;5;34m13,108,224\u001b[0m │ enc[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ dec[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m15\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ enc[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ encoder_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m526,336\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n","│ (\u001b[38;5;33mEncoderLayer\u001b[0m)      │                   │            │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ encoder_layer_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m526,336\u001b[0m │ encoder_layer[\u001b[38;5;34m0\u001b[0m]… │\n","│ (\u001b[38;5;33mEncoderLayer\u001b[0m)      │                   │            │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ encoder_layer_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m526,336\u001b[0m │ encoder_layer_1[\u001b[38;5;34m…\u001b[0m │\n","│ (\u001b[38;5;33mEncoderLayer\u001b[0m)      │                   │            │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dec[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m789,248\u001b[0m │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n","│ (\u001b[38;5;33mDecoderLayer\u001b[0m)      │                   │            │ encoder_layer_2[\u001b[38;5;34m…\u001b[0m │\n","│                     │                   │            │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n","│                     │                   │            │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_layer_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m789,248\u001b[0m │ decoder_layer[\u001b[38;5;34m0\u001b[0m]… │\n","│ (\u001b[38;5;33mDecoderLayer\u001b[0m)      │                   │            │ encoder_layer_2[\u001b[38;5;34m…\u001b[0m │\n","│                     │                   │            │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n","│                     │                   │            │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_layer_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m789,248\u001b[0m │ decoder_layer_1[\u001b[38;5;34m…\u001b[0m │\n","│ (\u001b[38;5;33mDecoderLayer\u001b[0m)      │                   │            │ encoder_layer_2[\u001b[38;5;34m…\u001b[0m │\n","│                     │                   │            │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n","│                     │                   │            │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_48 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m51204\u001b[0m) │ \u001b[38;5;34m13,159,428\u001b[0m │ decoder_layer_2[\u001b[38;5;34m…\u001b[0m │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ dec (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">13,108,224</span> │ enc[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ dec[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ encoder_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">526,336</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>)      │                   │            │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ encoder_layer_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">526,336</span> │ encoder_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>)      │                   │            │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ encoder_layer_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">526,336</span> │ encoder_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderLayer</span>)      │                   │            │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dec[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">789,248</span> │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderLayer</span>)      │                   │            │ encoder_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│                     │                   │            │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n","│                     │                   │            │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_layer_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">789,248</span> │ decoder_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderLayer</span>)      │                   │            │ encoder_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│                     │                   │            │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n","│                     │                   │            │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ decoder_layer_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">789,248</span> │ decoder_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderLayer</span>)      │                   │            │ encoder_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│                     │                   │            │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n","│                     │                   │            │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51204</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">13,159,428</span> │ decoder_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,214,404\u001b[0m (115.26 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,214,404</span> (115.26 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,214,404\u001b[0m (115.26 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,214,404</span> (115.26 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["initial_learning_rate = 5e-4\n","lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n","    initial_learning_rate,\n","    first_decay_steps=1000\n",")\n","optimizer = tf.keras.optimizers.Adam(lr_schedule)\n","\n","\n","model.compile(optimizer=optimizer,\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","history = model.fit([encoder_input, decoder_input], decoder_output,\n","          batch_size=64,\n","          epochs=20)\n"],"metadata":{"id":"hCV-SDbnUhf-","executionInfo":{"status":"ok","timestamp":1764254667340,"user_tz":-540,"elapsed":371758,"user":{"displayName":"Young-Min Kang","userId":"11805267479837045412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"157b47be-a970-427e-b459-04cb51e15b80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 137ms/step - accuracy: 0.3690 - loss: 6.3911\n","Epoch 2/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 0.4843 - loss: 3.4509\n","Epoch 3/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.5517 - loss: 3.1058\n","Epoch 4/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 88ms/step - accuracy: 0.5576 - loss: 3.0046\n","Epoch 5/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 88ms/step - accuracy: 0.5630 - loss: 2.9391\n","Epoch 6/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.5575 - loss: 2.9673\n","Epoch 7/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 98ms/step - accuracy: 0.5624 - loss: 2.9391\n","Epoch 8/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.5702 - loss: 2.8636\n","Epoch 9/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.5778 - loss: 2.7870\n","Epoch 10/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.5794 - loss: 2.7539\n","Epoch 11/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.5899 - loss: 2.6513\n","Epoch 12/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.5911 - loss: 2.6262\n","Epoch 13/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.5958 - loss: 2.5746\n","Epoch 14/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.5977 - loss: 2.5462\n","Epoch 15/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.6025 - loss: 2.5078\n","Epoch 16/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.6017 - loss: 2.5058\n","Epoch 17/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.5959 - loss: 2.5605\n","Epoch 18/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.5933 - loss: 2.5709\n","Epoch 19/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.6019 - loss: 2.4870\n","Epoch 20/20\n","\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.6071 - loss: 2.4221\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","def predict(sentence, max_len=MAX_LEN):\n","    # 1) 질문 전처리 & 토큰화\n","    sentence = clean_text(sentence)\n","    enc_input = encode_input(sentence)                 # (15,)\n","    enc_input = np.expand_dims(enc_input, 0)           # (1, 15)\n","\n","    # 2) 디코더 최초 입력은 <START> 만 넣고 나머지는 패딩\n","    dec_seq = np.full((1, max_len), PAD_ID, dtype=np.int32)\n","    dec_seq[0, 0] = START_ID                           # 첫 토큰 <START>\n","\n","    # 3) 토큰 하나씩 생성\n","    for i in range(1, max_len):\n","        # teacher-forcing 모델에 넣기\n","        preds = model.predict([enc_input, dec_seq], verbose=0)  # (1, 15, vocab)\n","        next_id = np.argmax(preds[0, i-1])               # greedy 선택\n","\n","        dec_seq[0, i] = next_id                          # 다음 입력에 반영\n","\n","        if next_id == END_ID:                            # <END> 이면 끝\n","            break\n","\n","    # 4) 생성된 토큰 ID → 한글 문장\n","    generated = dec_seq[0, 1:i]                          # <START> 제외\n","    text = tokenizer.decode(generated, skip_special_tokens=True)\n","    return text"],"metadata":{"id":"xcHSIGaPVgQ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["while True:\n","    input_string = input(\">>\")\n","    if input_string == 'exit':\n","        break\n","    print(predict(input_string))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kh___33pXKK1","executionInfo":{"status":"ok","timestamp":1764254843856,"user_tz":-540,"elapsed":176466,"user":{"displayName":"Young-Min Kang","userId":"11805267479837045412"}},"outputId":"bde1a963-4bb1-4b36-d0f0-e386daf4541a"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":[">>안녕\n","저도을 말고하봐 \n",">>오늘은 어때?\n","저도 쉬보면 마요\n",">>하하 재미있는 말이구나.\n","저도 쉬도 마요\n",">>저기 여행은 어디가 좋을까?\n","그은 흘네 \n",">>말을 아직 잘 못 하는구나\n","저도 쉬보면 마요\n",">>날씨가 춥다\n","저도을 말고 마봐 \n",">>exit\n"]}]},{"cell_type":"code","source":["# temperature 조정, 반복 패널티, top-k 샘플링 적용\n","import numpy as np\n","import tensorflow as tf\n","\n","def predict2(sentence,\n","            max_len=MAX_LEN,\n","            temperature=0.7,\n","            top_k=20,\n","            repetition_penalty=1.2):\n","    # 1) 질문 → 토큰\n","    sentence = clean_text(sentence)\n","    enc_in = np.expand_dims(encode_input(sentence), 0)   # (1, 15)\n","\n","    # 2) 디코더 초기 시퀀스\n","    dec_seq = np.full((1, max_len), PAD_ID, dtype=np.int32)\n","    dec_seq[0, 0] = START_ID\n","\n","    generated = []          # 이미 생성한 토큰 ID 보관\n","\n","    # 3) 토큰 하나씩 생성\n","    for i in range(1, max_len):\n","        preds = model.predict([enc_in, dec_seq], verbose=0)  # (1, 15, vocab)\n","        logits = preds[0, i-1]                              # (vocab,)\n","\n","        # 반복 페널티: 생성에 쓴 토큰은 로짓을 작게\n","        for token_id in generated:\n","            logits[token_id] /= repetition_penalty\n","\n","        # temperature + top-k\n","        logits = logits / temperature\n","        top_vals, top_inds = tf.nn.top_k(logits, k=top_k)\n","        probs = tf.nn.softmax(top_vals).numpy().ravel()\n","        next_id = np.random.choice(top_inds.numpy(), p=probs)\n","\n","        # 다음 입력에 반영\n","        dec_seq[0, i] = next_id\n","        generated.append(next_id)\n","\n","        if next_id == END_ID:        # <END> 만나면 끊기\n","            break\n","\n","    # 4) 토큰 → 한글\n","    text = tokenizer.decode(generated, skip_special_tokens=True)\n","    return text"],"metadata":{"id":"wXhiMp0cYSIv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["while True:\n","    input_string = input(\">>\")\n","    if input_string == 'exit':\n","        break\n","    print(predict2(input_string))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GXEkrOmRYmmG","executionInfo":{"status":"ok","timestamp":1764255079111,"user_tz":-540,"elapsed":235246,"user":{"displayName":"Young-Min Kang","userId":"11805267479837045412"}},"outputId":"d82b5504-d82d-49c2-a9c4-9eb92b6f09a0"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":[">>안녕?\n","또하 좋봐 니 \n",">>오늘은 날씨가 춥네\n","혼자하나어 찮요\n",">>늦게 퇴근하게 되었어\n","혼자는 관리 쉬 건에 \n",">>내일을 일찍 퇴근해야지\n","다른도하겠요\n",">>학교에 일찍 등교하려면 이제 퇴근해야지\n","사람 사람이니까 찮요\n",">>밖은 추우려나?\n","오늘도가요\n",">>exit\n"]}]}]}